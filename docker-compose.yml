services:
  # backend:
  #   build:
  #     dockerfile: Dockerfile
  #     context: .
  #   container_name: backend
  #   ports:
  #     - "8080:8080"
  #   env_file:
  #     - .env
  #   # depends_on:
  #     # - postgres
  #     # - redis
      
  # nginx:
  #   image: nginx:1.27
  #   container_name: logify_nginx
  #   ports:
  #     - "80:80"
  #   volumes:
  #     - ./nginx:/etc/nginx/conf.d:ro
  #   # depends_on:
  #     # - backend
  #   extra_hosts:
  #     - "host.docker.internal:host-gateway"

  # postgres:
  #   image: postgres:latest
  #   container_name: logify_postgres
  #   ports:
  #     - "5432:5432"
  #   environment:
  #     - POSTGRES_DB=postgres
  #     - POSTGRES_USER=postgres
  #     - POSTGRES_PASSWORD=postgres
  #   volumes:
  #     - postgres_data:/var/lib/postgresql/data

  # redis:
  #   image: redis:latest
  #   container_name: logify_redis
  #   ports:
  #     - "6371:6379"
  #   volumes:
  #     - redis_data:/data
  
  kafka:
    image: apache/kafka:3.9.0
    container_name: kafka
    user: "appuser:appuser"
    ports:
      - "9092:9092"
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: "broker,controller"
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka:9093"
      KAFKA_LISTENERS: INTERNAL://:29092,EXTERNAL://:9092,CONTROLLER://:9093
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka:29092,EXTERNAL://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "CONTROLLER:PLAINTEXT,INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT"
      KAFKA_INTER_BROKER_LISTENER_NAME: "INTERNAL"
      KAFKA_CONTROLLER_LISTENER_NAMES: "CONTROLLER"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      CLUSTER_ID: "LiKR6NrNSY2PVkX7d9kBiw"
      KAFKA_LOG_SEGMENT_BYTES: 536870912  # 100MB
      KAFKA_LOG_RETENTION_BYTES: 10737418240  # 10GB max retention per topic
      KAFKA_REPLICA_FETCH_MAX_BYTES: 104857600  # 100MB
      KAFKA_FETCH_MESSAGE_MAX_BYTES: 104857600  # 100MB
    volumes:
      - kafka_data:/var/lib/kafka/data
    networks:
      - logging-network
  
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    ports:
      - "8081:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:29092
      DYNAMIC_CONFIG_ENABLED: "true"
    depends_on:
      - kafka
    networks:
      - logging-network

  elasticsearch:
    image: elasticsearch:7.14.2
    container_name: elasticsearch
    ports:
      - "9200:9200"
    environment:
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      - discovery.type=single-node
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    networks:
      - logging-network
  
  opensearch:
    image: opensearchproject/opensearch:2.11.1
    container_name: opensearch-node1
    environment:
      - discovery.type=single-node
      - bootstrap.memory_lock=true
      - "OPENSEARCH_JAVA_OPTS=-Xms512m -Xmx512m"
      - "DISABLE_SECURITY_PLUGIN=true"
      # Elasticsearch compatibility settings
      - "COMPATIBILITY_MODE=true"
      - "compatibility.override_main_response_version=true"
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    ports:
      - 9200:9200
    healthcheck:
      test: ["CMD-SHELL", "curl -s http://localhost:9200/_cluster/health | grep -vq '\"status\":\"red\"'"]
      interval: 20s
      timeout: 10s
      retries: 3

networks:
  logging-network:
    driver: bridge

volumes:
  elasticsearch_data:
  kafka_data:
  postgres_data:
  redis_data: